{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Perception of the Sound ([Psychoacoustics](https://en.wikipedia.org/wiki/Psychoacoustics))\n",
    "\n",
    "* This chapter describes a psychoacoustic model for hearing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transduction\n",
    "* The human auditory system (HAS) is responsible for converting pressure variations caused by the sound waves (that reach the ear) in the synaptic signals that are interpreted by the brain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perception of sound intensity ([loudness](https://en.wikipedia.org/wiki/Loudness))\n",
    "\n",
    "* The relationship between the perceived volume of a sound and the actual volume of the sound is not linear, but logarithmic. For this reason, a decibel measurement of the sound intensity is the most appropriate to express this parameter.\n",
    "\n",
    "<img src=\"data/percepcion_de_la_intensidad_sonora.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Threshold of Hearing (ATH) [(Fletcher and Munson, 1933)](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Fletcher%2C+Munson%2C+loudness%2C+1933&btnG=)\n",
    "\n",
    "* The variation of what is perceived as equally loud at different frequencies was first measured by Fletcher and Munson at Bell Labs in the mid-1930s.\n",
    "\n",
    "* Humans ear better those sounds that contains audio signals with frequencies that ranges between 3 KHz and 4 KHz.\n",
    "\n",
    "<img src=\"data/ATHM.png\" width=600>\n",
    "\n",
    "* In lossy audio coding, where a quantizer controls the bit-rate, ff we select the quantizer step size such that the quantization noise lies below the audibility threshold, the noise will not be perceived.\n",
    "\n",
    "* The ATH shape depends on the noise level.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Lindos1.svg/500px-Lindos1.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency resolution and simultaneous (spectral) masking\n",
    "\n",
    "* The HAS has a limited frequency resolution. Psychoacoustic experiments have demonstrated that the audible frequencies can be grouped into barks.\n",
    "\n",
    "* Critical bands have a constant $Q$, which is the ratio of frequency to bandwidth. Thus, at low frequencies the critical band can have a bandwidth as low as 100 Hz, while at higher frequencies the bandwidth can be as large as 4 kHz.\n",
    "\n",
    "<img src=\"https://siemensplm.i.lithium.com/t5/image/serverpage/image-id/39831iEECD52574330B111/image-size/large?v=1.0&px=999\">\n",
    "\n",
    "<img src=\"data/anchos_de_banda_criticos.jpg\">\n",
    "\n",
    "* Each bark defines the group of frequencies that excite the same cochlear area, i.e., those frequencies that can be masked by the tone with the highest energy (in that bark).\n",
    "\n",
    "* As a consequence of this behavior, simultanous sounds with similar frequencies will mask each other.\n",
    "\n",
    "<img src=\"https://staff.fnwi.uva.nl/a.vaninge/MM/_images/simultaneousmasking.gif\">\n",
    "\n",
    "* Therefore, a tone at a certain frequency will raise the threshold in at least, a critical band around that frequency.\n",
    "\n",
    "* The degree to which the threshold is increased depends on a variety of factors, including whether the signal is [sinusoidal](https://en.wikipedia.org/wiki/Sine_wave) or [atonal](https://en.wikipedia.org/wiki/Atonality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal resolution and masking\n",
    "\n",
    "* The HAS has inertia. Sounds are not instantly perceived and remains (in our brain) for a while after they are disapered. Therefore, the HAS needs a minimum temporal separation between two sounds in order to distinguish a silence (independently of its frequencies).\n",
    "\n",
    "<img src=\"data/resolucion_temporal.jpg\">\n",
    "\n",
    "<img src=\"data/percepcion_temporal.png\" width=400>\n",
    "\n",
    "* [Temporal masking](https://en.wikipedia.org/wiki/Auditory_masking) occurs when the perception of one sound is inhibited by the presence of another sound.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/7/7a/Masker_increased_threshold.svg/480px-Masker_increased_threshold.svg.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binaural perception ([Sound localization](https://en.wikipedia.org/wiki/Sound_localization))\n",
    "\n",
    "* Human beings possess two ears that are separated a certain distance (the diameter of the head). Therefore, the sound they receive is almost never exactly the same.\n",
    "\n",
    "* This fact is used by the HAS to locate the sound sources. For this it uses that:\n",
    "\n",
    "    1. The level of sound intensity is always stronger in the ear that it is closer to the sound source.\n",
    "    2. As the time it takes sound waves coming from a source to reach the two ears is slightly different,\n",
    "     the brain is able to calculate the spatial location of the sound source.\n",
    "     \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/HRTF.svg/543px-HRTF.svg.png\">\n",
    "\n",
    "* Most audio codecs exploit this channel dependency by means of the [*joint stereo*](https://en.wikipedia.org/wiki/Joint_(audio_engineering)) mode, which encodes the $L$ and $R$ channels as\n",
    "\n",
    "  \\begin{equation}\n",
    "    M = \\displaystyle\\frac{L+R}{2}\n",
    "    \\tag{\"Mid\" signal}\n",
    "  \\end{equation}\n",
    "  \n",
    "   \\begin{equation}\n",
    "    S = \\displaystyle\\frac{L-R}{2}.\n",
    "    \\tag{\"Side\" signal}\n",
    "  \\end{equation}\n",
    "  \n",
    "  This processing is similar to [Dolby Stereo](https://en.wikipedia.org/wiki/Dolby_Stereo) for creating the surround channel, except than the surround ($S$) signal is generated by delaying one of the channels a small amount of time that depends on the intensity of the surround."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "\n",
    "Basically, removes pure signals of low amplitude but taking also into account the SAM (pSycho Acoustic Model) of the HAS (Human Auditory System). Noise use to be of low power!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lossy encoding\n",
    "The limitations of human perception are incorporated into the\n",
    "  compression process through the use of psychoacoustic models. Some of\n",
    "  these limitations are physiological, based on the machinery of\n",
    "  hearing. Others are psychological, based on how our brain processes\n",
    "  auditory stimuli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "1. https://ccrma.stanford.edu/~jos/bosse/\n",
    "2. https://en.wikibooks.org/wiki/Engineering_Acoustics/The_Human_Ear_and_Sound_Perception"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
